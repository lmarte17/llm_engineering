{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that provides detailed and descriptive answers to technical questions.\n",
    "Your responses should be in markdown format.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Let's break down the code snippet:\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "### Breakdown of the Code:\n",
       "\n",
       "1. **Set Comprehension**:\n",
       "   - The expression `{book.get(\"author\") for book in books if book.get(\"author\")}` is a **set comprehension**.\n",
       "   - This creates a **set** of authors from a collection of `books`, where each `book` is expected to be a dictionary (or an object that supports the `get` method).\n",
       "   - The `book.get(\"author\")` retrieves the value associated with the key `\"author\"` from each `book`.\n",
       "\n",
       "2. **Filtering Non-Empty Values**:\n",
       "   - The condition `if book.get(\"author\")` acts as a filter. It ensures that only books with a non-empty author string are included in the set. \n",
       "   - If `book.get(\"author\")` returns a falsy value (like `None`, an empty string, or `0`), that `book` will be excluded from the set.\n",
       "\n",
       "3. **Yielding from the Set**:\n",
       "   - The `yield from` statement is used in Python to delegate part of a generator function to another generator or iterable.\n",
       "   - It essentially yields each item from the iterable produced by the set comprehension one at a time.\n",
       "   - This means that if this line is inside a generator function, it allows the generator to sequentially yield each unique author from the set of `books`.\n",
       "\n",
       "### Purpose of the Code:\n",
       "\n",
       "- **Collecting Unique Authors**: The primary purpose of this code snippet is to gather unique authors from a list of books. Since sets automatically handle duplicates, using a set comprehension ensures that each author is only yielded once, even if several books share the same author.\n",
       "  \n",
       "- **Generator Function Context**: This code is likely part of a larger generator function that processes books. It could be used to iterate over unique authors without storing them in memory beyond the scope of the iteration.\n",
       "\n",
       "### Example for Clarity:\n",
       "\n",
       "Suppose we have the following list of books:\n",
       "\n",
       "python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Author A\"},  # Duplicate author\n",
       "    {\"title\": \"Book 4\", \"author\": \"\"},\n",
       "    {\"title\": \"Book 5\"},  # No author\n",
       "]\n",
       "\n",
       "\n",
       "Using the code snippet, the resulting unique authors would be:\n",
       "\n",
       "- Author A\n",
       "- Author B\n",
       "\n",
       "### Summary\n",
       "\n",
       "In summary, this line of code efficiently gathers and yields unique authors from a collection of book entries, ensuring that empty or missing authors are excluded and that duplicates are eliminated through the use of a set."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "answer = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in answer:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Code Explanation**\n",
       "=====================\n",
       "\n",
       "The given code is a generator expression that uses the `yield from` keyword to delegate iteration over a nested structure.\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "Here's a breakdown of what each part does:\n",
       "\n",
       "*   `{... for ...}`: This is a dictionary comprehension, which creates a new dictionary containing the results of iterating over the specified expression.\n",
       "*   `book.get(\"author\")`: For each book in the list, this expression retrieves the value associated with the key `\"author\"`. If the key does not exist (i.e., `book` is `None` or an empty string), it returns `None`.\n",
       "*   `books if book.get(\"author\")`: This is a conditional expression that filters out books where the `\"author\"` key does not exist. Only books with valid author information are included in the iteration.\n",
       "*   `yield from {...}`: The `yield from` keyword tells Python to delegate the iteration over the nested structure to the specified generator (in this case, the dictionary comprehension). This is useful when you want to lazily iterate over a complex data structure without having to load everything into memory at once.\n",
       "\n",
       "**Why Use `yield from`?**\n",
       "-------------------------\n",
       "\n",
       "The `yield from` keyword allows you to:\n",
       "\n",
       "*   **Avoid loading entire lists**: By using a generator expression with `yield from`, you can create an iterator that only loads the necessary data, which is more memory-efficient and suitable for large datasets.\n",
       "*   **Improve code readability**: The use of `yield from` clearly conveys your intention to delegate iteration over a nested structure, making it easier for other developers to understand the code.\n",
       "\n",
       "**Example Use Case**\n",
       "--------------------\n",
       "\n",
       "Suppose you have a list of book objects, each with an `\"author\"` key:\n",
       "python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": None},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Author C\"}\n",
       "]\n",
       "\n",
       "\n",
       "Using the provided code, you can create a generator that yields the author names of all books with valid author information:\n",
       "python\n",
       "gen = yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "for author in gen:\n",
       "    print(author)\n",
       "\n",
       "This will output:\n",
       "\n",
       "Author A\n",
       "Author C\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "answer = ollama.chat(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in answer:\n",
    "    response += chunk['message']['content'] or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
