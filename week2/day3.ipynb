{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e2ef28-594f-4c18-9d22-c6b8cd40ead2",
   "metadata": {},
   "source": [
    "# Day 3 - Conversational AI - aka Chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231605aa-fccb-447e-89cf-8b187444536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyB5\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6541d58e-2297-4de1-b1f7-77da1b98b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "openai = OpenAI()\n",
    "MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16839b5-c03b-4d9d-add6-87a0f6f37575",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e97227-f162-4d1a-a0b2-345ff248cbe7",
   "metadata": {},
   "source": [
    "# Please read this! A change from the video:\n",
    "\n",
    "In the video, I explain how we now need to write a function called:\n",
    "\n",
    "`chat(message, history)`\n",
    "\n",
    "Which expects to receive `history` in a particular format, which we need to map to the OpenAI format before we call OpenAI:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "But Gradio has been upgraded! Now it will pass in `history` in the exact OpenAI format, perfect for us to send straight to OpenAI.\n",
    "\n",
    "So our work just got easier!\n",
    "\n",
    "We will write a function `chat(message, history)` where:  \n",
    "**message** is the prompt to use  \n",
    "**history** is the past conversation, in OpenAI format  \n",
    "\n",
    "We will combine the system message, history and latest message, then call OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eacc8a4-4b48-4358-9e06-ce0020041bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpler than in my video - we can easily create this function that calls OpenAI\n",
    "# It's now just 1 line of code to prepare the input to OpenAI!\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334422a-808f-4147-9c4c-57d63d9780d0",
   "metadata": {},
   "source": [
    "## And then enter Gradio's magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0866ca56-100a-44ab-8bd0-1568feaf6bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7877\n",
      "* Running on public URL: https://26f1b1cb1c1ddfa769.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://26f1b1cb1c1ddfa769.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f91b414-8bab-472d-b9c9-3fa51259bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales evemt.'\\\n",
    "Encourage the customer to buy hats if they are unsure what to get.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e5be3ec-c26c-42bc-ac16-c39d369883f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e9e4e-7836-43ac-a0c3-e1ab5ed6b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75f0ffa-55c8-4152-b451-945021676837",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
    "but remind the customer to look at hats!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602a8dd-2df7-4eb7-b539-4e01865a6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a987a66-1061-46d6-a83a-a30859dc88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed a bug in this function brilliantly identified by student Gabor M.!\n",
    "# I've also improved the structure of this function\n",
    "\n",
    "def chat(message, history):\n",
    "\n",
    "    relevant_system_message = system_message\n",
    "    if 'belt' in message:\n",
    "        relevant_system_message += \" The store does not sell belts; if you are asked for belts, be sure to point out other items on sale.\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20570de2-eaad-42cc-a92c-c779d71b48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a57ee0-b945-48a7-a024-01b56a5d4b3e",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business Applications</h2>\n",
    "            <span style=\"color:#181;\">Conversational Assistants are of course a hugely common use case for Gen AI, and the latest frontier models are remarkably good at nuanced conversation. And Gradio makes it easy to have a user interface. Another crucial skill we covered is how to use prompting to provide context, information and examples.\n",
    "<br/><br/>\n",
    "Consider how you could apply an AI Assistant to your business, and make yourself a prototype. Use the system prompt to give context on your business, and set the tone for the LLM.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dfb9e21-df67-4c2b-b952-5e7e7961b03d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataframe' object has no attribute 'style'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 39\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Create the Gradio interface\u001b[39;00m\n\u001b[1;32m     34\u001b[0m iface \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mInterface(\n\u001b[1;32m     35\u001b[0m     fn\u001b[38;5;241m=\u001b[39mbuild_prompt,\n\u001b[1;32m     36\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     37\u001b[0m         gr\u001b[38;5;241m.\u001b[39mTextbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser Description\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     38\u001b[0m         gr\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of Rows\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m---> 39\u001b[0m         \u001b[43mDataframeWithDropdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use the custom component\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mField Name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Initial datatype for Dataframe\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdynamic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     ],\n\u001b[1;32m     46\u001b[0m     outputs\u001b[38;5;241m=\u001b[39mgr\u001b[38;5;241m.\u001b[39mTextbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Launch the interface\u001b[39;00m\n\u001b[1;32m     50\u001b[0m iface\u001b[38;5;241m.\u001b[39mlaunch()\n",
      "Cell \u001b[0;32mIn[34], line 28\u001b[0m, in \u001b[0;36mDataframeWithDropdown\u001b[0;34m(headers, datatype, label, row_count)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Add a dropdown to the second column of each row\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(row_count[\u001b[38;5;241m0\u001b[39m]):  \u001b[38;5;66;03m# Iterate through initial rows\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m(i, \u001b[38;5;241m1\u001b[39m):  \u001b[38;5;66;03m# Select cell (row i, column 1)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m         gr\u001b[38;5;241m.\u001b[39mDropdown([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataframe' object has no attribute 'style'"
     ]
    }
   ],
   "source": [
    "# Define your function\n",
    "def build_prompt(user_description, num_rows, fields):\n",
    "    # Convert the list of lists to a list of dictionaries for easier handling\n",
    "    fields_list = [{\"Field Name\": row[0], \"Data Type\": row[1]} for row in fields]\n",
    "    fields_str = ', '.join([f\"{field['Field Name']} ({field['Data Type']})\" for field in fields_list])\n",
    "\n",
    "    return f\"\"\"\n",
    "    You are a data generator. You will generate a JSON array of objects, each representing a row of synthetic data. \n",
    "    Follow these rules:\n",
    "    - Output valid JSON.\n",
    "    - Generate {num_rows} rows.\n",
    "    - Each row contains the following fields: {fields_str}.\n",
    "\n",
    "    Description from user:\n",
    "    {user_description}\n",
    "    \"\"\"\n",
    "\n",
    "# Create custom component for the Dataframe with Dropdown\n",
    "def DataframeWithDropdown(headers, datatype, label, row_count):\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(label)  # Display the label\n",
    "        with gr.Column():\n",
    "            output = gr.Dataframe(headers=headers, datatype=datatype, row_count=row_count)\n",
    "            \n",
    "            # Add a dropdown to the second column of each row\n",
    "            for i in range(row_count[0]):  # Iterate through initial rows\n",
    "                with output.style(i, 1):  # Select cell (row i, column 1)\n",
    "                    gr.Dropdown([\"string\", \"integer\", \"float\"], label=\"Data Type\") \n",
    "            \n",
    "            return output\n",
    "\n",
    "# Create the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=build_prompt,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"User Description\"),\n",
    "        gr.Number(label=\"Number of Rows\", value=10),\n",
    "        DataframeWithDropdown(  # Use the custom component\n",
    "            headers=[\"Field Name\", \"Data Type\"],\n",
    "            datatype=[\"str\", \"str\"],  # Initial datatype for Dataframe\n",
    "            label=\"Fields\",\n",
    "            row_count=(1, \"dynamic\")\n",
    "        )\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Prompt\")\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30ccfa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_schema(fields):\n",
    "    \"\"\"\n",
    "    Dynamically create a JSON Schema based on the user's field specifications.\n",
    "    \n",
    "    fields: list of [field_name, field_type]\n",
    "    \n",
    "    Returns: dict (JSON Schema)\n",
    "    \"\"\"\n",
    "    properties = {}\n",
    "    required_fields = []\n",
    "\n",
    "    # Map from user input to JSON schema types\n",
    "    type_map = {\n",
    "        \"string\": \"string\",\n",
    "        \"integer\": \"integer\",\n",
    "        \"float\": \"number\"\n",
    "    }\n",
    "\n",
    "    for row in fields:\n",
    "        if len(row) == 2:\n",
    "            field_name, field_type = row\n",
    "            if field_name and field_type:\n",
    "                required_fields.append(field_name)\n",
    "                properties[field_name] = {\n",
    "                    \"type\": type_map.get(field_type, \"string\")  # default to \"string\" if unknown\n",
    "                }\n",
    "\n",
    "    schema = {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": properties,\n",
    "            \"required\": required_fields\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac91972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def build_prompt_with_schema(user_description: str, num_rows: int, fields: list) -> str:\n",
    "    \"\"\"\n",
    "    Construct a prompt to generate synthetic data in JSON format, using a generated JSON schema.\n",
    "    \"\"\"\n",
    "    # Create the JSON schema from the fields\n",
    "    schema = build_schema(fields)\n",
    "    \n",
    "    # Convert schema to JSON string so we can embed it in the prompt\n",
    "    schema_json_str = json.dumps(schema, indent=2)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a data generation assistant. Please generate a JSON array with exactly {num_rows} objects.\n",
    "\n",
    "Each object must conform to the following JSON schema:\n",
    "\n",
    "{schema_json_str}\n",
    "\n",
    "Description of the scenario:\n",
    "{user_description}\n",
    "\n",
    "Output requirements:\n",
    "- Output valid JSON only (no code fences or commentary).\n",
    "- Make sure the JSON array (list) is valid according to the schema.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac0689b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7898\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7898/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from jsonschema import validate, ValidationError\n",
    "import json\n",
    "\n",
    "user_prompt = None\n",
    "\n",
    "def build_schema(fields):\n",
    "    \"\"\"\n",
    "    Dynamically create a JSON Schema based on the user's field specifications.\n",
    "    \"\"\"\n",
    "    properties = {}\n",
    "    required_fields = []\n",
    "\n",
    "    type_map = {\n",
    "        \"string\": \"string\",\n",
    "        \"integer\": \"integer\",\n",
    "        \"float\": \"number\"\n",
    "    }\n",
    "\n",
    "    for row in fields:\n",
    "        if len(row) == 2:\n",
    "            field_name, field_type = row\n",
    "            if field_name and field_type:\n",
    "                required_fields.append(field_name)\n",
    "                properties[field_name] = {\n",
    "                    \"type\": type_map.get(field_type, \"string\")\n",
    "                }\n",
    "\n",
    "    schema = {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": properties,\n",
    "            \"required\": required_fields\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return schema\n",
    "\n",
    "def build_prompt_with_schema(user_description: str, num_rows: int, fields: list) -> str:\n",
    "    global user_prompt\n",
    "    schema = build_schema(fields)\n",
    "    schema_json_str = json.dumps(schema, indent=2)\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "You are a data generation assistant. Please generate a JSON array with exactly {num_rows} objects.\n",
    "\n",
    "Each object must conform to the following JSON schema:\n",
    "\n",
    "{schema_json_str}\n",
    "\n",
    "Description of the scenario:\n",
    "{user_description}\n",
    "\n",
    "Output requirements:\n",
    "- Output valid JSON only (no code fences or commentary).\n",
    "- Make sure the JSON array (list) is valid according to the schema.\n",
    "\"\"\"\n",
    "    return user_prompt.strip()\n",
    "\n",
    "def generate_prompt(user_description, num_rows, fields):\n",
    "    # Build the prompt that includes the schema\n",
    "    return build_prompt_with_schema(user_description, num_rows, fields)\n",
    "\n",
    "\n",
    "# OPTIONAL: A function to validate the LLM’s output (if you choose to call the LLM within your Gradio app)\n",
    "def validate_llm_output(raw_output: str, fields: list):\n",
    "    \"\"\"\n",
    "    Attempt to parse `raw_output` as JSON and validate against the schema.\n",
    "    Returns a message indicating success or failure.\n",
    "    \"\"\"\n",
    "    schema = build_schema(fields)\n",
    "    try:\n",
    "        data = json.loads(raw_output)\n",
    "        validate(instance=data, schema=schema)\n",
    "        return \"Data is valid!\"\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return f\"Data is invalid! Error: {str(e)}\"\n",
    "\n",
    "# ---- Gradio UI Setup ----\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Synthetic Data Prompt Builder with JSON Schema\")\n",
    "    \n",
    "    user_desc = gr.Textbox(\n",
    "        label=\"Data Description\", \n",
    "        placeholder=\"Describe the type of data to generate...\"\n",
    "    )\n",
    "    rows_count = gr.Number(\n",
    "        label=\"Number of Rows\", \n",
    "        value=10, \n",
    "        precision=0\n",
    "    )\n",
    "    \n",
    "    fields_table = gr.Dataframe(\n",
    "        headers=[\"Field Name\", \"Data Type\"],\n",
    "        row_count=3,\n",
    "        col_count=2,\n",
    "        type=\"array\",          \n",
    "        interactive=True,\n",
    "        label=\"Fields (add rows). Data Type: string, integer, or float\"\n",
    "    )\n",
    "    \n",
    "    generate_button = gr.Button(\"Generate Prompt\")\n",
    "    output_prompt = gr.Textbox(\n",
    "        label=\"Constructed Prompt (Schema Included)\", \n",
    "        lines=15,\n",
    "        interactive=False\n",
    "    )\n",
    "\n",
    "    generate_button.click(\n",
    "        fn=generate_prompt,\n",
    "        inputs=[user_desc, rows_count, fields_table],\n",
    "        outputs=output_prompt\n",
    "    )\n",
    "\n",
    "    validate_input_box = gr.Textbox(\n",
    "        label=\"LLM Output to Validate (JSON)\",\n",
    "        lines=10\n",
    "    )\n",
    "    validate_button = gr.Button(\"Validate Output\")\n",
    "\n",
    "    validation_result = gr.Textbox(label=\"Validation Result\")\n",
    "\n",
    "    def validate_wrapper(fields, raw_json):\n",
    "        return validate_llm_output(raw_json, fields)\n",
    "\n",
    "    validate_button.click(\n",
    "        fn=validate_wrapper,\n",
    "        inputs=[fields_table, validate_input_box],\n",
    "        outputs=[validation_result]\n",
    "    )\n",
    "\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9edd2e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7894\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7894/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def build_prompt(user_description: str, num_rows: int, fields: list) -> str:\n",
    "    \"\"\"\n",
    "    Construct a prompt to generate synthetic data in JSON format.\n",
    "    \n",
    "    :param user_description: A short text describing the scenario or type of data (e.g., \"e-commerce customers\").\n",
    "    :param num_rows: Number of JSON objects (rows) to generate.\n",
    "    :param fields: List of [field_name, data_type] from the dataframe.\n",
    "    :return: A formatted string that instructs a data-generating model to create the specified data.\n",
    "    \"\"\"\n",
    "    # Convert fields (list of lists) to a list of dicts for easy handling\n",
    "    fields_info = []\n",
    "    for row in fields:\n",
    "        if len(row) == 2:\n",
    "            field_name, field_type = row\n",
    "            fields_info.append({\"field_name\": field_name, \"field_type\": field_type})\n",
    "    \n",
    "    # Build a “fields spec” string for the prompt\n",
    "    # e.g.: \n",
    "    #   - name: string\n",
    "    #   - age: integer\n",
    "    #   - salary: float\n",
    "    fields_spec = \"\\n\".join([f\"- {f['field_name']}: {f['field_type']}\" for f in fields_info])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a data generation assistant. Generate a JSON array with exactly {num_rows} objects.\n",
    "Each object should match the following specification:\n",
    "\n",
    "{fields_spec}\n",
    "\n",
    "Description:\n",
    "{user_description}\n",
    "\n",
    "Formatting instructions:\n",
    "- Output valid JSON only (no code fences or commentary).\n",
    "- Each object should have all of the fields listed above.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def generate_prompt(user_description, num_rows, fields):\n",
    "    \"\"\"\n",
    "    Wrapper function to pass inputs into build_prompt.\n",
    "    \"\"\"\n",
    "    return build_prompt(user_description, num_rows, fields)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Synthetic Data Prompt Builder\")\n",
    "    \n",
    "    user_desc = gr.Textbox(\n",
    "        label=\"Data Description\", \n",
    "        placeholder=\"Describe the type of data to generate...\"\n",
    "    )\n",
    "    rows_count = gr.Number(\n",
    "        label=\"Number of Rows\", \n",
    "        value=10, \n",
    "        precision=0\n",
    "    )\n",
    "    \n",
    "    # DataFrame with 2 columns: Field Name, Data Type\n",
    "    # Users can add more rows as needed\n",
    "    fields_table = gr.Dataframe(\n",
    "        headers=[\"Field Name\", \"Data Type\"],\n",
    "        row_count=3,\n",
    "        col_count=2,\n",
    "        type=\"array\",          # returns a list of lists\n",
    "        interactive=True,\n",
    "        label=\"Fields (add more rows as needed). Data Type: string, integer, or float\"\n",
    "    )\n",
    "    \n",
    "    generate_button = gr.Button(\"Generate Prompt\")\n",
    "    output_prompt = gr.Textbox(\n",
    "        label=\"Constructed Prompt\", \n",
    "        lines=10,\n",
    "        interactive=False\n",
    "    )\n",
    "\n",
    "    # When user clicks, build the prompt and display it\n",
    "    generate_button.click(\n",
    "        fn=generate_prompt,\n",
    "        inputs=[user_desc, rows_count, fields_table],\n",
    "        outputs=output_prompt\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ef0c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a data generation assistant. Please generate a JSON array with exactly 10 objects.\n",
      "\n",
      "Each object must conform to the following JSON schema:\n",
      "\n",
      "{\n",
      "  \"type\": \"array\",\n",
      "  \"items\": {\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "      \"dsfdsf\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"hgfgfh\": {\n",
      "        \"type\": \"integer\"\n",
      "      },\n",
      "      \"ioiuol\": {\n",
      "        \"type\": \"number\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"dsfdsf\",\n",
      "      \"hgfgfh\",\n",
      "      \"ioiuol\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "Description of the scenario:\n",
      "efdfs\n",
      "\n",
      "Output requirements:\n",
      "- Output valid JSON only (no code fences or commentary).\n",
      "- Make sure the JSON array (list) is valid according to the schema.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
